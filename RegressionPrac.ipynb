{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RegressionPrac",
      "provenance": [],
      "authorship_tag": "ABX9TyN7BMgD0tRfd/AuWmFyLsxi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/caxios/MachineLearningPythonPlayground/blob/main/RegressionPrac.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "KYlCo7dcCqbq"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.datasets import boston_housing \n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout \n",
        "from tensorflow.keras.layers import BatchNormalization \n",
        "from tensorflow.keras.callbacks import ModelCheckpoint # Use to save our model's parameters after each epoch of training.\n",
        "import os "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "1. What is Dropout and BatchNormaliztion?\n",
        ">> The Dropout layer randomly sets input units to 0 with a frequency of rate at each step during training time, which helps prevent overfitting.\n",
        "Batch normalization applies a transformation that maintains the mean output close to 0 and the output standard deviation close to 1.\n",
        "2. Why use BatchNormaliztion?\n",
        "src : https://www.analyticsvidhya.com/blog/2021/03/introduction-to-batch-normalization/\n",
        ">> Simply say, it enables us to train DNN faster and more stable. \n",
        "Normalization is a data pre-processing tool used to bring the numerical data to a common scale without distorting its shape. Generally, when we input \n",
        "the data to a machine or deep learning algorithm we tend to change the values to a  balanced scale. The reason we normalize is partly to ensure that our model \n",
        "can generalize appropriately. Batch normalization is a process to make neural networks faster and more stable through adding extra layers in a deep neural network. \n",
        "The new layer performs the standardizing and normalizing operations on the input of a layer coming from a previous layer.\n",
        "As the data go through multiple layers of the neural network and L activation functions are applied, it leads to an internal co-variate shift in the data.\n",
        "3. What is Dropout for?\n",
        ">> It is used to fix the over-fitting issue. Input data may have some of the unwanted data, usually called as Noise. Dropout will try to remove the noise data and \n",
        "thus prevent the model from over-fitting.\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        },
        "id": "DgJQPDEDO3Ec",
        "outputId": "489edd77-1b33-4575-b11d-0ab9a83365b1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n1. What is Dropout and BatchNormaliztion?\\n>> The Dropout layer randomly sets input units to 0 with a frequency of rate at each step during training time, which helps prevent overfitting.\\nBatch normalization applies a transformation that maintains the mean output close to 0 and the output standard deviation close to 1.\\n2. Why use BatchNormaliztion?\\nsrc : https://www.analyticsvidhya.com/blog/2021/03/introduction-to-batch-normalization/\\n>> Simply say, it enables us to train DNN faster and more stable. \\nNormalization is a data pre-processing tool used to bring the numerical data to a common scale without distorting its shape. Generally, when we input \\nthe data to a machine or deep learning algorithm we tend to change the values to a  balanced scale. The reason we normalize is partly to ensure that our model \\ncan generalize appropriately. Batch normalization is a process to make neural networks faster and more stable through adding extra layers in a deep neural network. \\nThe new layer performs the standardizing and normalizing operations on the input of a layer coming from a previous layer.\\nAs the data go through multiple layers of the neural network and L activation functions are applied, it leads to an internal co-variate shift in the data.\\n3. What is Dropout for?\\n>> It is used to fix the over-fitting issue. Input data may have some of the unwanted data, usually called as Noise. Dropout will try to remove the noise data and \\nthus prevent the model from over-fitting.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(X_train, y_train), (X_valid, y_valid) = boston_housing.load_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IiqLKz_MCwZY",
        "outputId": "2f60587f-e859-465e-8244-c1a76d06da96"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/boston_housing.npz\n",
            "57344/57026 [==============================] - 0s 0us/step\n",
            "65536/57026 [==================================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train.shape)\n",
        "print(X_train[0])\n",
        "print(y_train[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WYeQSaPtPN_O",
        "outputId": "b0b2a3aa-6089-404b-b293-6536ee2fabd5"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(404, 13)\n",
            "[  1.23247   0.        8.14      0.        0.538     6.142    91.7\n",
            "   3.9769    4.      307.       21.      396.9      18.72   ]\n",
            "15.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Design Nueral Network"
      ],
      "metadata": {
        "id": "I0VUmXKgWvaz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Dense(32, input_dim=13, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Dense(16, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "# Since we are predicting single value, house price, we make our output layer to have one nueron.\n",
        "model.add(Dense(1, activation='linear'))"
      ],
      "metadata": {
        "id": "U1zTZLdPPQqN"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Configure Model"
      ],
      "metadata": {
        "id": "fWmga6HDWsYI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Unlike in the classification task, in which we used metric of accuracy, we dont use that metric in regerssion model. Why?\n",
        "# Because calculating the probablilty of correctness of classification has no relevant to continous value output.\n",
        "model.compile(loss='mean_squared_error', optimizer='nadam')"
      ],
      "metadata": {
        "id": "iQkL4Fi-P3uR"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make directory to store model's parameters after each epoch of training.\n",
        "output_dir = 'model_output/'\n",
        "run_name = 'regression_baseline'"
      ],
      "metadata": {
        "id": "cmhiiF5DWEz3"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_path = output_dir + run_name"
      ],
      "metadata": {
        "id": "GYibgViMWJSy"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if not os.path.exists(output_path):\n",
        "    os.makedirs(output_path)"
      ],
      "metadata": {
        "id": "3-sKYdMKWLnL"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "modelcheckpoint = ModelCheckpoint(output_path + '/weights.{epoch:02d}.hdf5', \n",
        "                                  save_weights_only=True) "
      ],
      "metadata": {
        "id": "jcTEdR4RWOB5"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train"
      ],
      "metadata": {
        "id": "XZ_3CLjhWp1R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train, y_train, \n",
        "          batch_size=8, epochs=32, verbose=1, \n",
        "          validation_data=(X_valid, y_valid),\n",
        "          callbacks=[modelcheckpoint]) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Os1b7HUQdvu",
        "outputId": "e3a38c63-fe10-4765-d456-ad782160e82f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/32\n",
            "51/51 [==============================] - 2s 7ms/step - loss: 570.3697 - val_loss: 612.9385\n",
            "Epoch 2/32\n",
            "51/51 [==============================] - 0s 4ms/step - loss: 552.5043 - val_loss: 598.2256\n",
            "Epoch 3/32\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 531.6777 - val_loss: 593.5347\n",
            "Epoch 4/32\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 517.8016 - val_loss: 564.6739\n",
            "Epoch 5/32\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 488.7492 - val_loss: 559.8190\n",
            "Epoch 6/32\n",
            "51/51 [==============================] - 0s 4ms/step - loss: 462.8107 - val_loss: 567.9927\n",
            "Epoch 7/32\n",
            "51/51 [==============================] - 0s 4ms/step - loss: 430.1984 - val_loss: 560.5917\n",
            "Epoch 8/32\n",
            "51/51 [==============================] - 0s 4ms/step - loss: 385.8431 - val_loss: 693.7202\n",
            "Epoch 9/32\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 349.1447 - val_loss: 671.5432\n",
            "Epoch 10/32\n",
            "51/51 [==============================] - 0s 4ms/step - loss: 314.1806 - val_loss: 536.1432\n",
            "Epoch 11/32\n",
            "51/51 [==============================] - 0s 4ms/step - loss: 268.2284 - val_loss: 417.3332\n",
            "Epoch 12/32\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 228.8609 - val_loss: 395.2260\n",
            "Epoch 13/32\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 192.8094 - val_loss: 304.5140\n",
            "Epoch 14/32\n",
            "51/51 [==============================] - 0s 4ms/step - loss: 167.3596 - val_loss: 283.4659\n",
            "Epoch 15/32\n",
            "51/51 [==============================] - 0s 5ms/step - loss: 134.4042 - val_loss: 145.5437\n",
            "Epoch 16/32\n",
            "51/51 [==============================] - 0s 4ms/step - loss: 115.3724 - val_loss: 250.5480\n",
            "Epoch 17/32\n",
            "51/51 [==============================] - 0s 4ms/step - loss: 102.6273 - val_loss: 212.3137\n",
            "Epoch 18/32\n",
            "51/51 [==============================] - 0s 4ms/step - loss: 84.6281 - val_loss: 290.9523\n",
            "Epoch 19/32\n",
            "51/51 [==============================] - 0s 4ms/step - loss: 72.3135 - val_loss: 155.0838\n",
            "Epoch 20/32\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 69.6405 - val_loss: 176.4852\n",
            "Epoch 21/32\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 62.7784 - val_loss: 121.1243\n",
            "Epoch 22/32\n",
            "51/51 [==============================] - 0s 4ms/step - loss: 52.7638 - val_loss: 75.3443\n",
            "Epoch 23/32\n",
            "51/51 [==============================] - 0s 4ms/step - loss: 49.0706 - val_loss: 53.1974\n",
            "Epoch 24/32\n",
            "51/51 [==============================] - 0s 4ms/step - loss: 53.9193 - val_loss: 77.8085\n",
            "Epoch 25/32\n",
            "51/51 [==============================] - 0s 4ms/step - loss: 47.0160 - val_loss: 70.7287\n",
            "Epoch 26/32\n",
            "51/51 [==============================] - 0s 4ms/step - loss: 52.7054 - val_loss: 84.6076\n",
            "Epoch 27/32\n",
            "51/51 [==============================] - 0s 4ms/step - loss: 49.7733 - val_loss: 92.7921\n",
            "Epoch 28/32\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 47.9452 - val_loss: 117.8185\n",
            "Epoch 29/32\n",
            "51/51 [==============================] - 0s 4ms/step - loss: 42.0416 - val_loss: 84.8425\n",
            "Epoch 30/32\n",
            "51/51 [==============================] - 0s 4ms/step - loss: 51.5564 - val_loss: 52.1907\n",
            "Epoch 31/32\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 47.9051 - val_loss: 59.5526\n",
            "Epoch 32/32\n",
            "51/51 [==============================] - 0s 4ms/step - loss: 46.1982 - val_loss: 55.5225\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f039721af90>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Inference"
      ],
      "metadata": {
        "id": "bMUNLJ_sX4dG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_weights(output_path + '/weights.20.hdf5')"
      ],
      "metadata": {
        "id": "JS6_-8wvWTmi"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_valid[42])\n",
        "print(y_valid[42])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1uPChkQgZrTk",
        "outputId": "dc0339cf-a15f-42dd-87ec-397aefa40435"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[  9.32909   0.       18.1       0.        0.713     6.185    98.7\n",
            "   2.2616   24.      666.       20.2     396.9      18.13   ]\n",
            "14.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.predict(np.reshape(X_valid[42], [1, 13]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xqvIQdz1ZzR_",
        "outputId": "90fa8136-6a24-4a10-c026-39d4e18aba88"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[6.8623886]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "NebcQGx8TPg7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}