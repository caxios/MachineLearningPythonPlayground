{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNMAx0KsGjkrsblVPK8kOnt"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#MNIST 예시"
      ],
      "metadata": {
        "id": "EoGe7_Jg6mfD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "WgJu9Eq96l03"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "# 신경망 구축에 필요한 여러 매서드를 담은 torch.nn\n",
        "import torch.nn as nn\n",
        "# torch.nn의 모든 함수를 포함, 손실/활성화/풀링/합성곱/선형 및 기타 신경망 함수 가 포함됨\n",
        "import torch.nn.functional as F\n",
        "# 최적화(신경망의 가중치,매개변수 조정을 위해 오차를 역전파 하는 과정) 모듈이 담김\n",
        "import torch.optim as optim\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ConvNet(nn.Module):\n",
        "  \"\"\"\n",
        "  kernel_size : 보통 홀수. 너무 작으면 픽셀을 처리하는 kernel이 이웃 픽셀의 정보를 가지지 못한다.너무 크면 이미지 내에서 정밀하지\n",
        "                않은 특징을 얻게 됨. 작은 kernel_size의 많은 layer를 쓰면 네트워크가 깊어지고, 더 복잡한 특징 학습 가능.\n",
        "\n",
        "  feature map : 이미지 데이터에서 픽셀 정보를 담고 있는 channel(차원)을 의미. 이미지에서 더 많은 특징을 추출하려거든 channel을 크게\n",
        "                하면 된다.\n",
        "\n",
        "  input shape이 28x28x1임\n",
        "\n",
        "  Conv2d(input_channel, output_channel, kernel_size, stride)\n",
        "\n",
        "\n",
        "  \"\"\"\n",
        "  # 각 layer의 뉴런개수 및 layer들 정의\n",
        "  def __init__(self):\n",
        "    super(ConvNet, self).__init__()\n",
        "\n",
        "    # 합성곱 layer\n",
        "    self.cn1 = nn.Conv2d(1,16,3,1)\n",
        "    self.cn2 = nn.Conv2d(16,32,3,1)\n",
        "    # 드롭아웃 layer\n",
        "    self.dp1 = nn.Dropout(0.1)\n",
        "    self.dp2 = nn.Dropout(0.25)\n",
        "    # fully-connected(fc) layer, 4608=12x12x32\n",
        "    self.fc1 = nn.Linear(4608, 64)\n",
        "    # 최종 출력은 10개 클래스 중 하나\n",
        "    self.fc2 = nn.Linear(64,10)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.cn1(x)\n",
        "    x = F.relu(x)\n",
        "    x = self.cn2(x)\n",
        "    x = F.relu(x)\n",
        "    # kernel size가 2x2\n",
        "    x = F.max_pool2d(x,2)\n",
        "    x = self.dp1(x)\n",
        "    # 1차원 백터로 평면화\n",
        "    x = torch.flatten(x,1)\n",
        "    x = self.fc1(x)\n",
        "    x = F.relu(x)\n",
        "    x = self.dp2(x)\n",
        "    x = self.fc2(x)\n",
        "    # 모델의 예측을 out에 담음\n",
        "    out = F.log_softmax(x, dim=1)\n",
        "    return out"
      ],
      "metadata": {
        "id": "DYydgv6t6zdy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}