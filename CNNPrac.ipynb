{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNNPrac",
      "provenance": [],
      "authorship_tag": "ABX9TyOKJyXLhGlvvN5t0gMpCswU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/caxios/MachineLearningPythonPlayground/blob/main/CNNPrac.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "RqqUxsFY7ueu"
      },
      "outputs": [],
      "source": [
        "import tensorflow\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.layers import Flatten, Conv2D, MaxPooling2D "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "1. Why use Conv2D layer even we can use Dense layer for MNIST classification?\n",
        ">> Because for the computer vision, using convolutional neural network is much efficient than just using deep nerual network. And its dimension is 2D because we are\n",
        "dealing with just hand-written digit images.\n",
        "2. Why use Flatten?\n",
        ">> Since Dense layer can only handle input of 1-dimension data, we need to flatten data that is generated from Conv2D layer.\n",
        "3. Why use pooling?\n",
        ">> Pooling allow us to reduce unnecessary computational loads, the memory usage, and the number of parameters and therby limiting risk of overfitting.\n",
        "Also Reducing the input image size also makes the neural network tolerate a little bit of image shift which mean our model can handle much more general images, not\n",
        "only applicable to one specific image.\n",
        "Pooling layer is consists of pooling neurons. Pooling neuron is connected to the outputs of a limited number of neurons in the previous layer, however unlike\n",
        "it is the case for Dense layer's neuron, pooling neurons in pooling layer have no weights. All it does is aggregate the inputs using an aggregation function \n",
        "such as the max or mean. MaxPooling is just one of the common type of pooling layer.\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        },
        "id": "u03u8K3R76b4",
        "outputId": "6b5fb7da-17c5-4d95-c693-624bb5f4017b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\n1. Why use Conv2D layer even we can use Dense layer for MNIST classification?\\n>> Because for the computer vision, using convolutional neural network is much efficient than just using deep nerual network. And its dimension is 2D because we are\\ndealing with just hand-written digit images.\\n2. Why use Flatten?\\n>> Since Dense layer can only handle input of 1-dimension data, we need to flatten data that is generated from Conv2D layer.\\n3. Why use pooling?\\n>> Pooling allow us to reduce unnecessary computational loads, the memory usage, and the number of parameters and therby limiting risk of overfitting.\\nAlso Reducing the input image size also makes the neural network tolerate a little bit of image shift which mean our model can handle much more general images, not\\nonly applicable to one specific image.\\nPooling layer is consists of pooling neurons. Pooling neuron is connected to the outputs of a limited number of neurons in the previous layer, however unlike\\nit is the case for Dense layer's neuron, pooling neurons in pooling layer have no weights. All it does is aggregate the inputs using an aggregation function \\nsuch as the max or mean. MaxPooling is just one of the common type of pooling layer.\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(X_train, y_train), (X_valid, y_valid) = mnist.load_data()\n",
        "# Since we are using Conv2D layer, which is capable of working with 2d data, we don't need to convert our image data into 1-dimenstion which means\n",
        "# we don't have to flatten our 28*28 image into 784 1D data. \n",
        "# And fourth dimension is 1, and it indicates that we are dealing with black-white(monochrome) image, not colored image.\n",
        "X_train = X_train.reshape(60000, 28, 28, 1).astype('float32') \n",
        "X_valid = X_valid.reshape(10000, 28, 28, 1).astype('float32')\n",
        "X_train /= 255\n",
        "X_valid /= 255\n",
        "n_classes = 10\n",
        "y_train = to_categorical(y_train, n_classes)\n",
        "y_valid = to_categorical(y_valid, n_classes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kiCQRmkH7ykz",
        "outputId": "79895437-2c55-4c37-f3c7-0e0657f44e85"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1))) # kernel_size = filter size\n",
        "\n",
        "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(4, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(n_classes, activation='softmax'))"
      ],
      "metadata": {
        "id": "N8BRs4mS74yM"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "1. Why I increased Dropout rate?\n",
        ">> Increase Dropout rate in order to prevent model from overfitting. Deeper the layer can learn some complex features from training data. The problem of learning\n",
        "something complex feature from traning data is that model performe well on traning set whereas cannot perform on the unseen data, which means overfitting.\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "tOREOmY1DWM1",
        "outputId": "69b493d3-8828-49ad-89fc-b557efe5035c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n1. Why I increased Dropout rate?\\n>> Increase Dropout rate in order to prevent model from overfitting. Deeper the layer can learn some complex features from training data. The problem of learning\\nsomething complex feature from traning data is that model performe well on traning set whereas cannot perform on the unseen data, which means overfitting.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MOAvh4xo8Bxo",
        "outputId": "cf043bea-f4c0-49cf-8352-40a2ed600ac2"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 26, 26, 32)        320       \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 24, 24, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 6, 12, 64)        0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 6, 12, 64)         0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 4608)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               589952    \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 610,058\n",
            "Trainable params: 610,058\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Configure model"
      ],
      "metadata": {
        "id": "sgN59Bk_8IK5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='nadam', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "nnei8OHS8DR-"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train model"
      ],
      "metadata": {
        "id": "ILQUZz2a8LNN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train, y_train, batch_size=128, epochs=10, verbose=1, validation_data=(X_valid, y_valid))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E-CyJTZU8J3o",
        "outputId": "5383f256-db88-4be3-d0a5-a32c56c92f9b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "469/469 [==============================] - 21s 18ms/step - loss: 0.2584 - accuracy: 0.9205 - val_loss: 0.0535 - val_accuracy: 0.9842\n",
            "Epoch 2/10\n",
            "469/469 [==============================] - 8s 17ms/step - loss: 0.0878 - accuracy: 0.9738 - val_loss: 0.0444 - val_accuracy: 0.9849\n",
            "Epoch 3/10\n",
            "469/469 [==============================] - 8s 17ms/step - loss: 0.0665 - accuracy: 0.9792 - val_loss: 0.0335 - val_accuracy: 0.9893\n",
            "Epoch 4/10\n",
            "469/469 [==============================] - 8s 17ms/step - loss: 0.0561 - accuracy: 0.9827 - val_loss: 0.0343 - val_accuracy: 0.9889\n",
            "Epoch 5/10\n",
            "469/469 [==============================] - 8s 17ms/step - loss: 0.0492 - accuracy: 0.9848 - val_loss: 0.0288 - val_accuracy: 0.9910\n",
            "Epoch 6/10\n",
            "469/469 [==============================] - 8s 17ms/step - loss: 0.0432 - accuracy: 0.9864 - val_loss: 0.0261 - val_accuracy: 0.9916\n",
            "Epoch 7/10\n",
            "469/469 [==============================] - 8s 17ms/step - loss: 0.0375 - accuracy: 0.9884 - val_loss: 0.0248 - val_accuracy: 0.9923\n",
            "Epoch 8/10\n",
            "469/469 [==============================] - 8s 17ms/step - loss: 0.0346 - accuracy: 0.9892 - val_loss: 0.0249 - val_accuracy: 0.9918\n",
            "Epoch 9/10\n",
            "469/469 [==============================] - 8s 17ms/step - loss: 0.0317 - accuracy: 0.9901 - val_loss: 0.0249 - val_accuracy: 0.9916\n",
            "Epoch 10/10\n",
            "469/469 [==============================] - 8s 17ms/step - loss: 0.0281 - accuracy: 0.9906 - val_loss: 0.0268 - val_accuracy: 0.9911\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fcfcdca20d0>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(X_valid, y_valid)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BlrzbgwuFomN",
        "outputId": "e58edd3b-5dbd-448c-9a43-b71ebca30abc"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 2s 5ms/step - loss: 0.0268 - accuracy: 0.9911\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.026792209595441818, 0.991100013256073]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_valid_0 = X_valid[0].reshape(1, 28, 28, 1).astype(\"float32\")\n",
        "model.predict(x_valid_0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RQyYq0NS8Mg3",
        "outputId": "e829a8eb-a29a-435f-dbd3-cbf4a4137d0d"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[2.30287198e-13, 7.85320198e-10, 2.02566386e-09, 6.20609653e-09,\n",
              "        1.22211226e-11, 6.65823245e-13, 1.06269144e-18, 1.00000000e+00,\n",
              "        3.84934055e-12, 2.43732075e-08]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    }
  ]
}